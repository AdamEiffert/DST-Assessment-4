{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247dce79",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc999d72",
   "metadata": {},
   "source": [
    "## Activation Function and Model depth\n",
    "Across the 3 approaches we found that tanh has a reduced performance across more complex models (both an increase in depth and the number of classifications), while being fairly quick in training the models both in total time but also across a single epoch. Swish has an increase in accuracy and AUC across complexity when compared to the other activation functions and generally performs fairly quickly in total time but is slighlty slower across a single epoch, although this is by a small absolute amount. RELU, on the other hand, performs fairly well across the board in accuracy and AUC with no clear link to complexity. However, RELU often was the worst at total training time even if it was generally quickest across a single epoch. \n",
    "\n",
    "In all for models of low depth (less than 5) then tanh is a good choice, while any more than that Swish is a good activation function. RELU is consistent across all depths but the much greater training time is important to note. While this is what our data shows much more data would be required to provide a confident analysis of the activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427dc4e2",
   "metadata": {},
   "source": [
    "## Adversarial attack \n",
    "Then we performed adversarial attacks to the Neural Network models with same parameters as the last part, but fixed epoches. After that, we re-trained model by inputting the adversarial examples generated in the first attack along with the raw input. \n",
    "\n",
    "In conclusion, three types of activation functions have no significant impact on performances against the attacks both before and after adversarial trainings. The effect of adversarial trainings only appears when when epsilon is large, and they improve the robustness more when the number of layers increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565a6a6",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "\n",
    "* This was the first time that we were able to use the HPC, which mean that we needed to learn how to effectively balance resource management with queueing times, as asking for more resources e.g. memory would lead to a longer wait in the queue. Here we suffered with long queue times which limited the number of times we could run the code and when we needed rerun the code to correct the generated models and the confusion matrices, we were unable to due to the long queue times. \n",
    "\n",
    "* Repeating the experiment multiple would have helped provide assurance that the results were correct. Another way to help increase our confidence in our results is by looking at more depths of models (1-10) would have helped provide a clearer picture of how the activations functions were affected by the depth of the models.\n",
    "\n",
    "* It would have been better if we were able to optimise our analysis to help provide better conclusions. First, it would have been nice to analyse the confusion matrices for the different classifications to see if there were any obvious patterns. On top of this, the average time across depths graphs provided no useful information as this result was expected as a deeper model takes longer to train, so this could have been removed. \n",
    "\n",
    "* It would have been nicer to have had either a fixed number of epochs or a more explorative trainer as this would have allowed us to get more information out of the accuracy and AUC change over time. Our results only provided a few epochs to look at and so we were not able to see any trends here.\n",
    "\n",
    "* We decided on this dataset because it was easy to preprocess as we had already dealt with it beforehand. Maybe using a different dataset could have provided a clearer difference between the accuracy and AUC across the different models. This is because dataset we used was very clean and so allowed for high accuracy models but meant it was harder to differenciate the models' accuracy and AUC with confidence given their similarity in performance. \n",
    "\n",
    "* It seems obvious now, however the task of trying to see how activation functions are affected by the depth of models is much too big to do effectively in such a timescale. It would have been much more satisfying to be confident in our results, but this project does provide a possible hypothesis for further and more conclusive testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c673df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
